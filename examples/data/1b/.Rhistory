library(shiny); runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
POST(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&concepts=gene")
library(httr)
POST(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&concepts=gene")
hallo= POST(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&concepts=gene")
hallo
hallo$content
hallo$headers
GET(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&concepts=gene")
GET("http://google.com/", path = "search", query = list(q = "ham"))
GET(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&concepts=gene")
GET(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577/17922911&concepts=gene")
GET(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&17922911&concepts=gene")
hallo=GET(url="https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=28483577&17922911&concepts=gene")
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.deploy/genes/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.deploy/researchers/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.deploy/researchers/T6_SimTextApp.R')
library(shiny); runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.deploy/genes/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
runApp('Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/Shinyapp.development/T6_SimTextApp.R')
install.packages("caTools")
parser <- ArgumentParser()
parser$add_argument("-i", "--input",
help = "input fie name. add path if file is not in workind directory")
parser$add_argument("-o", "--output", default="T3_output",
help = "output file name. [default \"%(default)s\"]")
parser$add_argument("-n", "--number", type="integer", default=50, choices=seq(1, 500), metavar="{0..500}",
help="number of most frequent words used per ID in word matrix [default \"%(default)s\"]")
parser$add_argument("-r", "--remove_num", action="store_true", default=FALSE,
help= "remove any numbers in text")
parser$add_argument("-l", "--lower_case", action="store_false", default=TRUE,
help="by default all characters are translated to lower case. otherwise use -l")
parser$add_argument("-w", "--remove_stopwords", action="store_false", default=TRUE,
help="by default a set of English stopwords (e.g., 'the' or 'not') are removed. otherwise use -s")
parser$add_argument("-s", "--stemDoc", action="store_true", default=FALSE,
help="apply Porter's stemming algorithm: collapsing words to a common root to aid comparison of vocabulary")
parser$add_argument("-p", "--plurals", action="store_false", default=TRUE,
help="by default words in plural and singular are merged to the singular form. otherwise use -p")
args <- parser$parse_args()
if (!require('argparse')) install.packages('argparse'); suppressPackageStartupMessages(library("argparse"))
parser <- ArgumentParser()
parser$add_argument("-i", "--input",
help = "input fie name. add path if file is not in workind directory")
parser$add_argument("-o", "--output", default="T3_output",
help = "output file name. [default \"%(default)s\"]")
parser$add_argument("-n", "--number", type="integer", default=50, choices=seq(1, 500), metavar="{0..500}",
help="number of most frequent words used per ID in word matrix [default \"%(default)s\"]")
parser$add_argument("-r", "--remove_num", action="store_true", default=FALSE,
help= "remove any numbers in text")
parser$add_argument("-l", "--lower_case", action="store_false", default=TRUE,
help="by default all characters are translated to lower case. otherwise use -l")
parser$add_argument("-w", "--remove_stopwords", action="store_false", default=TRUE,
help="by default a set of English stopwords (e.g., 'the' or 'not') are removed. otherwise use -s")
parser$add_argument("-s", "--stemDoc", action="store_true", default=FALSE,
help="apply Porter's stemming algorithm: collapsing words to a common root to aid comparison of vocabulary")
parser$add_argument("-p", "--plurals", action="store_false", default=TRUE,
help="by default words in plural and singular are merged to the singular form. otherwise use -p")
args <- parser$parse_args()
NULL +5
0+5
setwd("~/Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/SimText/test")
if (!require('argparse')) install.packages('argparse'); suppressPackageStartupMessages(library("argparse"))
if (!require("PubMedWordcloud")) install.packages("PubMedWordcloud"); library("PubMedWordcloud")
if (!require('SnowballC')) install.packages('SnowballC'); suppressPackageStartupMessages(library("SnowballC"))
if (!require('SemNetCleaner')) install.packages('SemNetCleaner'); suppressPackageStartupMessages(library("SemNetCleaner"))
parser <- ArgumentParser()
parser$add_argument("-i", "--input",
help = "input fie name. add path if file is not in workind directory")
parser$add_argument("-o", "--output", default="text_to_wordmatrix_output",
help = "output file name. [default \"%(default)s\"]")
parser$add_argument("-n", "--number", type="integer", default=50, choices=seq(1, 500), metavar="{0..500}",
help="number of most frequent words used per ID in word matrix [default \"%(default)s\"]")
parser$add_argument("-r", "--remove_num", action="store_true", default=FALSE,
help= "remove any numbers in text")
parser$add_argument("-l", "--lower_case", action="store_false", default=TRUE,
help="by default all characters are translated to lower case. otherwise use -l")
parser$add_argument("-w", "--remove_stopwords", action="store_false", default=TRUE,
help="by default a set of English stopwords (e.g., 'the' or 'not') are removed. otherwise use -s")
parser$add_argument("-s", "--stemDoc", action="store_true", default=FALSE,
help="apply Porter's stemming algorithm: collapsing words to a common root to aid comparison of vocabulary")
parser$add_argument("-p", "--plurals", action="store_false", default=TRUE,
help="by default words in plural and singular are merged to the singular form. otherwise use -p")
args <- parser$parse_args()
data = read.delim(args$input, stringsAsFactors=FALSE, header = TRUE, sep='\t')
args$input = data/test_data
args$input = "data/test_data"
args$matrix = "data/text_to_wordmatrix_output"
args
data = read.delim(args$input, stringsAsFactors=FALSE, header = TRUE, sep='\t')
word_matrix = data.frame()
text_cols_index <- grep(c("ABSTRACT|TEXT"), names(data))
args$input = "data/pubmed_by_queries_output_abstracts"
data = read.delim(args$input, stringsAsFactors=FALSE, header = TRUE, sep='\t')
word_matrix = data.frame()
text_cols_index <- grep(c("ABSTRACT|TEXT"), names(data))
for(row in 1:nrow(data)){
top_words = cleanAbstracts(abstracts= data[row,text_cols_index],
rmNum = args$remove_num,
tolw= args$lower_case,
rmWords= args$remove_stopwords,
stemDoc= args$stemDoc)
top_words$word <- as.character(top_words$word)
cat("Top words for row", row, " are extracted.", "\n")
if(args$plurals == TRUE){
top_words$word <- sapply(top_words$word, function(x){singularize(x)})
top_words = aggregate(freq~word,top_words,sum)
}
top_words = top_words[order(top_words$freq, decreasing = TRUE), ]
top_words$word = as.character(top_words$word)
number_extract = min(args$number, nrow(top_words))
word_matrix[row,sapply(1:number_extract, function(x){paste0(top_words$word[x])})] <- top_words$freq[1:number_extract]
}
warnings()
word_matrix <- as.matrix(word_matrix)
word_matrix[is.na(word_matrix)] <- 0
word_matrix <- word_matrix>0 *1  #binary matrix
for(row in 1:nrow(data)){
top_words = cleanAbstracts(abstracts= data[row,text_cols_index],
rmNum = args$remove_num,
tolw= args$lower_case,
rmWords= args$remove_stopwords,
stemDoc= args$stemDoc)
top_words$word <- as.character(top_words$word)
cat("Most frequent words for row", row, " are extracted.", "\n")
if(args$plurals == TRUE){
top_words$word <- sapply(top_words$word, function(x){singularize(x)})
top_words = aggregate(freq~word,top_words,sum)
}
top_words = top_words[order(top_words$freq, decreasing = TRUE), ]
top_words$word = as.character(top_words$word)
number_extract = min(args$number, nrow(top_words))
word_matrix[row,sapply(1:number_extract, function(x){paste0(top_words$word[x])})] <- top_words$freq[1:number_extract]
}
word_matrix <- as.matrix(word_matrix)
word_matrix[is.na(word_matrix)] <- 0
word_matrix <- (word_matrix>0) *1  #binary matrix
cat("A matrix with ", nrow(word_matrix), " rows and ", ncol(word_matrix), "columns is generated.", "\n")
write.table(word_matrix, args$output, row.names = FALSE, sep = '\t')
ifelse(500 < 51, c(1,1), c(0.5,0.5))
ifelse(5 < 51, c(1,1), c(0.5,0.5))
setwd("~/Dropbox/LAL_PROJECTS/RESEARCH_PORTAL/SimText/examples/data/1b")
matrix = read.delim("clingen_data_matrix", stringsAsFactors=FALSE)
matrix =  (as.matrix(matrix)>0) *1 #transform matrix to binary matrix
colSums(matrix)
colsum_data= data.frame(word=colnames(matrix), freq=colSums(matrix))
colsum_data = colsum_data[order(colsum_data$freq, decreasing = T),]
colnames(colsum_data) = c("Word", paste0("IDs (total n=", nrow(matrix),")"))
datatable(colsum_data,
extensions = c("Buttons"),
rownames = F,
fillContainer = T,
escape=FALSE,
options = list(dom = "t",
scrollY = min(nrow(colsum_data),500),
scrollX= TRUE,
scroller = TRUE,
pageLength = nrow(colsum_data),
columnDefs = list(list(className = 'dt-center', targets = "_all")))
1+1
ID_matrix = matrix[1,]
ID_matrix = data.frame(word= names(ID_matrix), freq= t(ID_matrix))
colnames(ID_matrix) = c("word", "freq")
ID_matrix = matrix[index_ID(),]
matrix = as.data.frame(matrix)
ID_matrix = matrix[1,]
ID_matrix = data.frame(word= names(ID_matrix), freq= t(ID_matrix))
colnames(ID_matrix) = c("word", "freq")
ID_matrix = ID_matrix[ID_matrix$freq > 0,]
ID_matrix
matrix = as.data.frame(matrix)
ID_matrix = matrix[index_ID(),]
ID_matrix = matrix[1,]
